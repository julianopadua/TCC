{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f7cce2",
   "metadata": {},
   "source": [
    "# TCC Focos de Queimadas no Cerrado\n",
    "## Entendimento inicial da base INMET + BDQueimadas\n",
    "\n",
    "Este caderno implementa a etapa 1 da análise: inspeção e auditoria de qualidade dos arquivos ano a ano no padrão `data/dataset/inmet_bdq_{ANO}_cerrado.csv`. O foco aqui é medir:\n",
    "\n",
    "1. Proporção de HAS_FOCO por ano.\n",
    "2. Ocorrência de valores sentinela em qualquer coluna numérica: -999, -9999, 999, 9999.\n",
    "3. Entre as linhas com foco, quantas contêm sentinelas negativos (-999 ou -9999).\n",
    "\n",
    "Observação de parsing: os CSVs usam vírgula como separador decimal em diversas colunas. Usaremos `decimal=','` no carregamento e coerção numérica laxa para auditoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd0fe3",
   "metadata": {},
   "source": [
    "## Sumário\n",
    "\n",
    "1. [Configuração e imports](#configuracao-e-imports)\n",
    "2. [Parâmetros do projeto e diretórios](#parametros-do-projeto-e-diretorios)\n",
    "3. [Funções de descoberta e leitura](#funcoes-de-descoberta-e-leitura)\n",
    "4. [Coerção numérica e sentinelas](#coercao-numerica-e-sentinelas)\n",
    "5. [Métricas por ano](#metricas-por-ano)\n",
    "6. [Pipeline de auditoria](#pipeline-de-auditoria)\n",
    "7. [Execução e persistência do resumo](#execucao-e-persistencia-do-resumo)\n",
    "8. [Visualizações rápidas](#visualizacoes-rapidas)\n",
    "9. [Sanity check com 2003](#sanity-check-com-2003)\n",
    "10. [Próximos passos](#proximos-passos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc835f4",
   "metadata": {},
   "source": [
    "## 1. Configuração e imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3962c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf932e",
   "metadata": {},
   "source": [
    "## 2. Parâmetros do projeto e diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc4aae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Diretório não encontrado: D:\\Projetos\\TCC\\src\\data\\dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m FILENAME_PATTERN = \u001b[33m\"\u001b[39m\u001b[33minmet_bdq_*_cerrado.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Valida diretórios\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m DATASET_DIR.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDiretório não encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset dir:\u001b[39m\u001b[33m\"\u001b[39m, DATASET_DIR)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mReports dir:\u001b[39m\u001b[33m\"\u001b[39m, REPORTS_DIR)\n",
      "\u001b[31mAssertionError\u001b[39m: Diretório não encontrado: D:\\Projetos\\TCC\\src\\data\\dataset"
     ]
    }
   ],
   "source": [
    "# Raiz do projeto e subpastas relevantes\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "DATASET_DIR = PROJECT_ROOT / \"data\" / \"dataset\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\" / \"eda\"\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Padrão de nome dos arquivos ano a ano\n",
    "FILENAME_PATTERN = \"inmet_bdq_*_cerrado.csv\"\n",
    "\n",
    "# Valida diretórios\n",
    "assert DATASET_DIR.exists(), f\"Diretório não encontrado: {DATASET_DIR}\"\n",
    "print(\"Dataset dir:\", DATASET_DIR)\n",
    "print(\"Reports dir:\", REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e9c20",
   "metadata": {},
   "source": [
    "## 3. Funções de descoberta e leitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692f56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_minimal_has_foco(path: Path) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Lê apenas HAS_FOCO; retorna Series int64 {0,1}.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, dtype=str, usecols=[\"HAS_FOCO\"], low_memory=False, encoding=\"utf-8\")\n",
    "    return pd.to_numeric(df[\"HAS_FOCO\"], errors=\"coerce\").fillna(0).astype(\"int64\")\n",
    "\n",
    "def summarize_file(year: int, path: Path) -> dict:\n",
    "    s = load_minimal_has_foco(path)\n",
    "    n_rows = int(s.shape[0])\n",
    "    n_focos = int((s == 1).sum())\n",
    "    prop = float(n_focos / n_rows) if n_rows > 0 else 0.0\n",
    "    return {\"year\": year, \"file\": str(path), \"rows\": n_rows, \"focos\": n_focos, \"prop_foco\": prop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5321573",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m      4\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNenhum arquivo encontrado em \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m com padrão inmet_bdq_\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33mYYYY\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBIOME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDica: verifique a célula 0 para a lista de arquivos detectados.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m summary_rows = [\u001b[43msummarize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y, p \u001b[38;5;129;01min\u001b[39;00m files]\n\u001b[32m      9\u001b[39m summary_df = pd.DataFrame(summary_rows).sort_values(\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m summary_df_style = (\n\u001b[32m     12\u001b[39m     summary_df\n\u001b[32m     13\u001b[39m     .assign(prop_foco_pct=(summary_df[\u001b[33m\"\u001b[39m\u001b[33mprop_foco\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[32m100.0\u001b[39m))\n\u001b[32m     14\u001b[39m     .drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mprop_foco\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     15\u001b[39m     .rename(columns={\u001b[33m\"\u001b[39m\u001b[33mprop_foco_pct\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mprop_foco(\u001b[39m\u001b[33m%\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36msummarize_file\u001b[39m\u001b[34m(year, path)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msummarize_file\u001b[39m(year: \u001b[38;5;28mint\u001b[39m, path: Path) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     s = \u001b[43mload_minimal_has_foco\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     n_rows = \u001b[38;5;28mint\u001b[39m(s.shape[\u001b[32m0\u001b[39m])\n\u001b[32m     11\u001b[39m     n_focos = \u001b[38;5;28mint\u001b[39m((s == \u001b[32m1\u001b[39m).sum())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_minimal_has_foco\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_minimal_has_foco\u001b[39m(path: Path) -> pd.Series:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Lê apenas HAS_FOCO; retorna Series int64 {0,1}.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHAS_FOCO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.to_numeric(df[\u001b[33m\"\u001b[39m\u001b[33mHAS_FOCO\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m).fillna(\u001b[32m0\u001b[39m).astype(\u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projetos\\TCC\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projetos\\TCC\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projetos\\TCC\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projetos\\TCC\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first_chunk:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "files = find_dataset_files(BIOME, YEARS)\n",
    "if not files:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Nenhum arquivo encontrado em {DATASET_DIR} com padrão inmet_bdq_{{YYYY}}_{BIOME}.csv.\\n\"\n",
    "        f\"Dica: verifique a célula 0 para a lista de arquivos detectados.\"\n",
    "    )\n",
    "\n",
    "summary_rows = [summarize_file(y, p) for y, p in files]\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"year\").reset_index(drop=True)\n",
    "\n",
    "summary_df_style = (\n",
    "    summary_df\n",
    "    .assign(prop_foco_pct=(summary_df[\"prop_foco\"] * 100.0))\n",
    "    .drop(columns=[\"prop_foco\"])\n",
    "    .rename(columns={\"prop_foco_pct\": \"prop_foco(%)\"})\n",
    ")\n",
    "summary_df_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38acc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anos_cobertos</th>\n",
       "      <th>arquivos</th>\n",
       "      <th>linhas_total</th>\n",
       "      <th>focos_total</th>\n",
       "      <th>prop_foco_total(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003–2024</td>\n",
       "      <td>20</td>\n",
       "      <td>45135924</td>\n",
       "      <td>151544</td>\n",
       "      <td>0.33575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anos_cobertos  arquivos  linhas_total  focos_total  prop_foco_total(%)\n",
       "0     2003–2024        20      45135924       151544             0.33575"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = int(summary_df[\"rows\"].sum())\n",
    "total_focos = int(summary_df[\"focos\"].sum())\n",
    "total_prop  = float(total_focos / total_rows) if total_rows > 0 else 0.0\n",
    "\n",
    "totais = pd.DataFrame([{\n",
    "    \"anos_cobertos\": (\n",
    "        f\"{summary_df['year'].min()}–{summary_df['year'].max()}\"\n",
    "        if len(summary_df) > 1 else f\"{summary_df['year'].iloc[0]}\"\n",
    "    ),\n",
    "    \"arquivos\": len(summary_df),\n",
    "    \"linhas_total\": total_rows,\n",
    "    \"focos_total\": total_focos,\n",
    "    \"prop_foco_total(%)\": total_prop * 100.0,\n",
    "}])\n",
    "totais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc1138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>file</th>\n",
       "      <th>rows</th>\n",
       "      <th>focos</th>\n",
       "      <th>prop_foco_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>D:\\Projetos\\TCC\\data\\dataset\\inmet_bdq_2024_ce...</td>\n",
       "      <td>3161880</td>\n",
       "      <td>12740</td>\n",
       "      <td>0.402925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               file     rows  focos  \\\n",
       "0  2024  D:\\Projetos\\TCC\\data\\dataset\\inmet_bdq_2024_ce...  3161880  12740   \n",
       "\n",
       "   prop_foco_pct  \n",
       "0       0.402925  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIOME = \"cerrado\"\n",
    "YEARS = [2024]\n",
    "files_2003 = find_dataset_files(BIOME, YEARS)\n",
    "if not files_2003:\n",
    "    raise FileNotFoundError(\"Arquivo 2003 não encontrado (veja a lista na Célula 0).\")\n",
    "\n",
    "y, p = files_2003[0]\n",
    "one = summarize_file(y, p)\n",
    "pd.DataFrame([one]).assign(prop_foco_pct=lambda d: d[\"prop_foco\"] * 100).drop(columns=[\"prop_foco\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
